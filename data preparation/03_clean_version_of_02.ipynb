{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clean_version.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ycF0f_O-TYVR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Test data from our github repo\n",
        "url_test = 'https://raw.githubusercontent.com/tjayada/iANNwTF_Project/main/data/Test.csv'\n",
        "dataDF_test = pd.read_csv(url_test)\n",
        "\n",
        "# Load Train data from our github repo\n",
        "url_train = 'https://raw.githubusercontent.com/tjayada/iANNwTF_Project/main/data/Train.csv'\n",
        "dataDF_train = pd.read_csv(url_train)"
      ],
      "metadata": {
        "id": "uog2ddieTsac"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data without clomumns 70 - 76 and drop NaN's\n",
        "\n",
        "# for test date\n",
        "data_without_columns_test = dataDF_test.copy()\n",
        "data_without_columns_test = data_without_columns_test.drop([\"L3_CH4_CH4_column_volume_mixing_ratio_dry_air\", \"L3_CH4_aerosol_height\", \"L3_CH4_aerosol_optical_depth\",\n",
        "                                      \"L3_CH4_sensor_azimuth_angle\", \"L3_CH4_sensor_zenith_angle\", \"L3_CH4_solar_azimuth_angle\", \"L3_CH4_solar_zenith_angle\"], axis=1)\n",
        "data_without_columns_test = data_without_columns_test.dropna()\n",
        "\n",
        "# for train data\n",
        "data_without_columns_train = dataDF_train.copy()\n",
        "data_without_columns_train = data_without_columns_train.drop([\"L3_CH4_CH4_column_volume_mixing_ratio_dry_air\", \"L3_CH4_aerosol_height\", \"L3_CH4_aerosol_optical_depth\",\n",
        "                                      \"L3_CH4_sensor_azimuth_angle\", \"L3_CH4_sensor_zenith_angle\", \"L3_CH4_solar_azimuth_angle\", \"L3_CH4_solar_zenith_angle\"], axis=1)\n",
        "data_without_columns_train = data_without_columns_train.dropna()"
      ],
      "metadata": {
        "id": "XcyzWUidTwzN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove targets and create labels\n",
        "\n",
        "data_without_columns_train_labels = data_without_columns_train[['target']]\n",
        "data_without_columns_train = data_without_columns_train.drop([\"target\", \"target_min\", \"target_max\", \"target_variance\", \"target_count\"], axis=1)"
      ],
      "metadata": {
        "id": "tx4gOHZwU8zX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "\n",
        "# for test data\n",
        "x = data_without_columns_test.iloc[:,3:]\n",
        "data_without_columns_test.iloc[:,3:] = (x-x.min())/ (x.max() - x.min())\n",
        "\n",
        "# for train data\n",
        "x = data_without_columns_train.iloc[:,3:]\n",
        "data_without_columns_train.iloc[:,3:] = (x-x.min())/ (x.max() - x.min())"
      ],
      "metadata": {
        "id": "ZV1qTxytXE8I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dates to datetime\n",
        "\n",
        "data_without_columns_test['date'] = pd.to_datetime(data_without_columns_test['Date'],format='%Y-%m-%d')\n",
        "data_without_columns_train['date'] = pd.to_datetime(data_without_columns_train['Date'],format='%Y-%m-%d')\n",
        "\n",
        "\n",
        "# add weekdays based on dates\n",
        "\n",
        "data_without_columns_test['weekday'] = data_without_columns_test['date'].dt.weekday\n",
        "data_without_columns_train['weekday'] = data_without_columns_train['date'].dt.weekday\n",
        "\n",
        "\n",
        "# add month based on dates\n",
        "\n",
        "data_without_columns_test['month'] = data_without_columns_test['date'].dt.month\n",
        "data_without_columns_train['month'] = data_without_columns_train['date'].dt.month"
      ],
      "metadata": {
        "id": "G07l8YNJYCd4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################################################################################################"
      ],
      "metadata": {
        "id": "3t3wvLqqaqp6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create data set with mean values as replacement for NaN's\n",
        "\n",
        "# for test data\n",
        "data_with_mean_NaN_test = dataDF_test.copy()\n",
        "data_with_mean_NaN_test = data_with_mean_NaN_test.fillna(data_with_mean_NaN_test.mean())\n",
        "\n",
        "# for train data\n",
        "data_with_mean_NaN_train = dataDF_train.copy()\n",
        "data_with_mean_NaN_train = data_with_mean_NaN_train.fillna(data_with_mean_NaN_train.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ntnA-Daw5Y",
        "outputId": "79bb2ed2-f4e0-4358-cee9-0329852c5209"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove targets and create labels\n",
        "\n",
        "data_with_mean_NaN_train_labels = data_with_mean_NaN_train[['target']]\n",
        "data_with_mean_NaN_train = data_with_mean_NaN_train.drop([\"target\", \"target_min\", \"target_max\", \"target_variance\", \"target_count\"], axis=1)"
      ],
      "metadata": {
        "id": "83EIexqhcEqE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "\n",
        "# for test data\n",
        "x = data_with_mean_NaN_test.iloc[:,3:]\n",
        "data_with_mean_NaN_test.iloc[:,3:] = (x-x.min())/ (x.max() - x.min())\n",
        "\n",
        "# for train data\n",
        "x = data_with_mean_NaN_train.iloc[:,3:]\n",
        "data_with_mean_NaN_train.iloc[:,3:] = (x-x.min())/ (x.max() - x.min())"
      ],
      "metadata": {
        "id": "lXLdFxOAcNuX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dates to datetime\n",
        "\n",
        "data_with_mean_NaN_test['date'] = pd.to_datetime(data_with_mean_NaN_test['Date'],format='%Y-%m-%d')\n",
        "data_with_mean_NaN_train['date'] = pd.to_datetime(data_with_mean_NaN_train['Date'],format='%Y-%m-%d')\n",
        "\n",
        "\n",
        "# add weekdays based on dates\n",
        "\n",
        "data_with_mean_NaN_test['weekday'] = data_with_mean_NaN_test['date'].dt.weekday\n",
        "data_with_mean_NaN_train['weekday'] = data_with_mean_NaN_train['date'].dt.weekday\n",
        "\n",
        "\n",
        "# add month based on dates\n",
        "\n",
        "data_with_mean_NaN_test['month'] = data_with_mean_NaN_test['date'].dt.month\n",
        "data_with_mean_NaN_train['month'] = data_with_mean_NaN_train['date'].dt.month"
      ],
      "metadata": {
        "id": "x-qXiNWncZDV"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}